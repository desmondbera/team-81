{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ab70386",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3f9b4efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****\n"
     ]
    }
   ],
   "source": [
    "df_2016_2015 = pd.read_csv('data_cleaning/clean_df_2016-2015.csv')\n",
    "df_2017_2016 = pd.read_csv('data_cleaning/clean_df_2017-2016.csv')\n",
    "\n",
    "df_2018_2017 = pd.read_csv('data_cleaning/clean_df_2018-2017.csv')\n",
    "df_2019_2018 = pd.read_csv('data_cleaning/clean_df_2019-2018.csv')\n",
    "\n",
    "df_2020 = pd.read_csv('data_cleaning/clean_df_2020-2019.csv')\n",
    "\n",
    "# print(df_2016_2015.columns)\n",
    "\n",
    "# print(\"=====\")\n",
    "# print(df_2017_2016.columns)\n",
    "# print(\"=====\")\n",
    "# print(df_2018_2017.columns)\n",
    "# print(\"=====\")\n",
    "# print(df_2019_2018.columns)\n",
    "# print(\"=====\")\n",
    "# print(df_2020.columns)\n",
    "# # print(df_2016_2015.info)\n",
    "# # print(df_2017_2016.columns)\n",
    "# print(\"=====\")\n",
    "\n",
    "df_2016_2015.drop(columns='Unnamed: 0', inplace=True)\n",
    "df_2018_2017.drop(columns='Unnamed: 0', inplace=True)\n",
    "df_2019_2018.drop(columns='Unnamed: 0', inplace=True)\n",
    "df_2020.drop(columns='Unnamed: 0', inplace=True)\n",
    "\n",
    "# print(df_2019_2018.columns)\n",
    "print(\"****\")\n",
    "# df_2020 = df_2020.rename(columns={'american indian/alaskan native removals and/or suspensions resulting from incidents where nypd was contacted': 'american indian/alaskan native removals or suspensions resulting from incidents where nypd was contacted'})\n",
    "# df_2020 = df_2020.rename(columns={'asian removals and/or suspensions resulting from incidents where nypd was contacted': 'asian removals or suspensions resulting from incidents where nypd was contacted'})\n",
    "# df_2020 = df_2020.rename(columns={'black removals and/or suspensions resulting from incidents where nypd was contacted': 'black removals or suspensions resulting from incidents where nypd was contacted'})\n",
    "# df_2020 = df_2020.rename(columns={'hispanic removals and/or suspensions resulting from incidents where nypd was contacted':'hispanic removals or suspensions resulting from incidents where nypd was contacted'})\n",
    "# df_2020 = df_2020.rename(columns={'white removals and/or suspensions resulting from incidents where nypd was contacted':'white removals or suspensions resulting from incidents where nypd was contacted'})\n",
    "# df_2020 = df_2020.rename(columns={'multi-racial removals and/or suspensions resulting from incidents where nypd was contacted':'multi-racial removals or suspensions resulting from incidents where nypd was contacted'})\n",
    "# df_2020 = (\n",
    "#     df_2020.rename(\n",
    "#         columns={\n",
    "#             'unknown removals and/or suspensions resulting from incidents where nypd was contacted':'unknown removals or suspensions resulting from incidents where nypd was contacted',\n",
    "#             'female removals and/or suspensions resulting from incidents where nypd was contacted':'female removals or suspensions resulting from incidents where nypd was contacted',\n",
    "#             'male removals and/or suspensions resulting from incidents where nypd was contacted':'male removals or suspensions resulting from incidents where nypd was contacted',\n",
    "#             'sy1920_total_removals_suspensions removals and/or suspensions resulting from incidents where nypd was contacted':'total removals or suspensions resulting from incidents where nypd was contacted'\n",
    "#         })\n",
    "# )\n",
    "\n",
    "\n",
    "# print(df_2020.columns)\n",
    "# output1 = pd.merge(df_2016_2015, df_2017_2016, on='DBN', how='inner')\n",
    "# print(output1.columns)\n",
    "\n",
    "# merged_2016_and_2015 = df_2016_2015.set_index('DBN').join(df_2017_2016.set_index('DBN'), lsuffix='_16-15', rsuffix='_17-16')\n",
    "# merged_2017_to_2015 =  \n",
    "df_2016_2015.merge(df_2017_2016, on='DBN', how='outer', suffixes=('_16-15', '_17-16'))\n",
    "\n",
    "# df_2018_2017.set_index('DBN').join(df_2019_2018.set_index('DBN'), lsuffix='_18-17', how='outer', rsuffix='_19-18')\n",
    "# merged_2019_to_2017 =\n",
    "df_2018_2017.merge(df_2019_2018, on='DBN', how='outer', suffixes=('_17-18', '_19-18'))\n",
    "# print(output_2.columns)\n",
    "\n",
    "\n",
    "# merged_2019_to_2017.merge(merged_2017_to_2015, on='DBN', how='outer', suffixes=('_TEST_X', '_TEST_Y'))\n",
    "\n",
    "\n",
    "\n",
    "# final = \n",
    "# 'american indian/alaskan native removals and/or suspensions resulting from incidents where nypd was contacted'\n",
    "# 'american indian/alaskan native removals or suspensions resulting from incidents where nypd was contacted'\n",
    "\n",
    "# 'asian removals or suspensions resulting from incidents where nypd was contacted'\n",
    "# 'asian removals and/or suspensions resulting from incidents where nypd was contacted',\n",
    "cols_to_merge_on = [ 'american indian/alaskan native removals and/or suspensions resulting from incidents where nypd was contacted',\n",
    "       'asian removals or suspensions resulting from incidents where nypd was contacted',\n",
    "       'black removals or suspensions resulting from incidents where nypd was contacted',\n",
    "       'hispanic removals or suspensions resulting from incidents where nypd was contacted',\n",
    "       'white removals or suspensions resulting from incidents where nypd was contacted',\n",
    "       'multi-racial removals or suspensions resulting from incidents where nypd was contacted',\n",
    "       'unknown removals or suspensions resulting from incidents where nypd was contacted',\n",
    "       'principal', 'removal', 'superintendent', 'expulsions',\n",
    "       'female removals or suspensions resulting from incidents where nypd was contacted',\n",
    "       'male removals or suspensions resulting from incidents where nypd was contacted',\n",
    "       'total removals or suspensions resulting from incidents where nypd was contacted']\n",
    "# df_2020.merge(df_2019_2018[cols_for_2019_2018], on='DBN', how='left')\n",
    "\n",
    "# pd.merge(df_2020, df_2019_2018, on=cols_for_2019_2018, how='outer')\n",
    "# result = \n",
    "# pd.concat([df_2020, df_2019_2018], axis=0)\n",
    "\n",
    "# pd.merge(df_2020, df_2019_2018, on='DBN', how='outer')\n",
    "\n",
    "# pd.concat([df_2016_2015, pd.DataFrame(columns=)])\n",
    "\n",
    "# df_2020.insert(0, 'test_col', df_2019_2018['principal'])\n",
    "# print((df_2019_2018['principal']))\n",
    "# print(df_2020['principal'])\n",
    "# df_2020 = df_2020.assign(principal_2019_2018=[df_2019_2018['principal']])\n",
    "# print(df_2019_2018.columns.tolist()[4:])\n",
    "df_2020_2019_old_names = df_2020.columns.tolist()[4:]\n",
    "df_2019_2018_old_names = df_2019_2018.columns.tolist()[4:]\n",
    "df_2018_2017_old_names = df_2018_2017.columns.tolist()[4:]\n",
    "df_2017_2016_old_names = df_2017_2016.columns.tolist()[4:]\n",
    "df_2016_2015_old_names = df_2016_2015.columns.tolist()[4:]\n",
    "# print(len(df_2019_2018_cols_to_rename))\n",
    "\n",
    "df_2020_2019_new_names = []\n",
    "for col in df_2020_2019_old_names:\n",
    "    df_2020_2019_new_names.append(col + '_2020_2019')\n",
    "\n",
    "df_2019_2018_new_names = []\n",
    "for col in df_2019_2018_old_names:\n",
    "    df_2019_2018_new_names.append(col + '_2019_2018')\n",
    "\n",
    "df_2018_2017_new_names = []\n",
    "for col in df_2018_2017_old_names:\n",
    "    df_2018_2017_new_names.append(col + '_2018_2017')\n",
    "# print(df_2019_2018_new_names)\n",
    "\n",
    "df_2017_2016_new_names = []\n",
    "for col in df_2017_2016_old_names:\n",
    "    df_2017_2016_new_names.append(col + '_2017_2016')\n",
    "    \n",
    "df_2016_2015_new_names = []\n",
    "for col in df_2016_2015_old_names:\n",
    "    df_2016_2015_new_names.append(col + '_2016_2015')\n",
    "\n",
    "    \n",
    "df_2020.rename(columns=dict(zip(df_2020_2019_old_names, df_2020_2019_new_names)), inplace=True)\n",
    "df_2019_2018.rename(columns=dict(zip(df_2019_2018_old_names, df_2019_2018_new_names)), inplace=True)\n",
    "df_2018_2017.rename(columns=dict(zip(df_2018_2017_old_names, df_2018_2017_new_names)), inplace=True)\n",
    "df_2017_2016.rename(columns=dict(zip(df_2017_2016_old_names, df_2017_2016_new_names)), inplace=True)\n",
    "df_2016_2015.rename(columns=dict(zip(df_2016_2015_old_names, df_2016_2015_new_names)), inplace=True)\n",
    "\n",
    "cols_to_add_20_19 = df_2020.columns.tolist()[4:]\n",
    "cols_to_add_19_18 = df_2019_2018.columns.tolist()[4:]\n",
    "cols_to_add_18_17 = df_2018_2017.columns.tolist()[4:]\n",
    "cols_to_add_17_16 = df_2017_2016.columns.tolist()[4:]\n",
    "cols_to_add_16_15 = df_2016_2015.columns.tolist()[4:]\n",
    "# print(cols_to_add_18_17)\n",
    "\n",
    "df_2020_2018 = pd.concat([df_2020, df_2019_2018[cols_to_add_19_18]], axis=1, verify_integrity=True)\n",
    "df_2020_2017 = pd.concat([df_2020_2018, df_2018_2017[cols_to_add_18_17]], axis=1, verify_integrity=True)\n",
    "df_2020_2016 = pd.concat([df_2020_2017, df_2017_2016[cols_to_add_17_16]], axis=1, verify_integrity=True)\n",
    "df_2020_2016 = pd.concat([df_2020_2016, df_2016_2015[cols_to_add_16_15]], axis=1, verify_integrity=True)\n",
    "# df_2020\n",
    "# print(df_2020_2017.columns.tolist())\n",
    "# print(df_2020_2016.columns.tolist())\n",
    "\n",
    "df_2020_2016.to_csv('final_2020_to_2016.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a48200",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f885698",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
